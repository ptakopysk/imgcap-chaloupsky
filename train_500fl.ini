[vars]
datapref="/home/rosa/lustre_rosa/chaloupsky/data"

[main]
name="EN Image Captioning on 500 descriptions of 100 images from Flickr30k"
tf_manager=<tf_manager>
output="experiments/captioning_500fl"
batch_size=64
epochs=60
train_dataset=<train_data>
val_dataset=<val_data>
trainer=<trainer>
runners=[<runner>,<ppl_runner>]
postprocess=None
evaluation=[("target", "targetmulti", <bleu1>), ("perplexity", "target", <perplexity>), ("target", "targetmulti", <bleu4>)]
logging_period="30s"
validation_period="600s"
runners_batch_size=100
random_seed=123

[bleu4]
class=evaluators.bleu.BLEUEvaluator
name="BLEU-4"
multiple_references_separator="###"
n=4

[bleu1]
class=evaluators.bleu.BLEUEvaluator
name="BLEU-1"
multiple_references_separator="###"
n=1

[tf_manager]
class=tf_manager.TensorFlowManager
num_threads=12
save_n_best=5
num_sessions=1
minimize_metric=False

[perplexity]
class=evaluators.AverageEvaluator
name="perplexity"

[train_imagenet_reader]
class=readers.numpy_reader.from_file_list
prefix="{datapref}/images_500fl_preprocessed"

[val_imagenet_reader]
class=readers.numpy_reader.from_file_list
prefix="{datapref}/val_images_100fl_preprocessed"

[train_data]
class=dataset.load_dataset_from_files
s_images=("{datapref}/images_500fl_preprocessed.txt", <train_imagenet_reader>)
s_target="{datapref}/labels_500fl.txt"
s_targetmulti="{datapref}/labels_500fl.txt"
lazy=True

[val_data]
class=dataset.load_dataset_from_files
s_images=("{datapref}/val_images_100fl_preprocessed.txt", <val_imagenet_reader>)
s_target="{datapref}/val_labels_single_100fl.txt"
s_targetmulti="{datapref}/val_labels_multi_100fl.txt"

[imagenet_resnet]
class=encoders.numpy_stateful_filler.SpatialFiller
name="imagenet"
input_shape=[8, 8, 2048]
data_id="images"

[tgt_vocabulary]
class=vocabulary.from_wordlist
path="{datapref}/en.vocab"

[attention]
class=attention.Attention
name="img_attention"
encoder=<imagenet_resnet>
state_size=2048

[decoder]
class=decoders.decoder.Decoder
name="decoder"
encoders=[<imagenet_resnet>]
attentions=[<attention>]
vocabulary=<tgt_vocabulary>
data_id="target"
conditional_gru=True
rnn_size=1024
max_output_len=40
dropout_keep_prob=0.5
embedding_size=500
attention_on_input=False

[trainer]
class=trainers.cross_entropy_trainer.CrossEntropyTrainer
decoders=[<decoder>]
clip_norm=1.0

[runner]
class=runners.runner.GreedyRunner
decoder=<decoder>
output_series="target"

[ppl_runner]
class=runners.PerplexityRunner
output_series="perplexity"
decoder=<decoder>

